During the last half year I've spent more than 200 hours on development on the caldav library and related projects.  This is a lot more than the estimate in the road map.  Reasons for this:

* Of course, taking care of issues not related to the roadmap as they're coming in.  All since summer I've been quite busy with other problems, not having time to focus on the CalDAV library.  Development goes slower when there are long interruptions, as context is forgotten, and it also means there are more issues, pull requests etc requiring attention.
* Communication, bug reporting, collaboration with other actors, server developers etc
* I have been encouraged to fork out things not directly related to the core business of the CalDAV client library into separate packages.  This has resulted in two spin-off-packages:
  * icalendar-searcher - do filtering and sorting of icalendar data.  To have consistent search results from all the different servers out there, it's needed to do client-side filtering, but this logic may be useful beyond the caldav.  A lot of work has been put down into making this a modern package following all the current best practices, and decoupling it from the internals of the caldav library.  The caldav library depends on icalendar-searcher.  All changes in icalendar-searcher relevant for the caldav library has to be released and published before the CI pipelines at GitHub can pass.  This also adds extra overhead.
  * caldav-server-tester - a stand-alone package dependent on caldav.  My local test runs of caldav also depends on caldav-server-tester.  This package is not so well polished, but it adds complexity to the development as changes in the caldav-server-tester has to be done in lock-steps with the changes in the caldav testing framework and compatibility hints database, and a new release of the caldav-server-tester should be published right after the caldav library is released.
* Functional tests towards slow caldav servers worked in one moment, and then it suddenly fails in the next moment.  It may be due to changes done on the server side, but it may also be me introducing some new compatibility-problems in the caldav library.  With three separate packages, I found tools like git bisect to be ineffective.
* I have now two frameworks for organizing information about caldav server features - the old style boolean "incompatibility flags" that has become a bit unwieldy and inconsistent - and the new style "feature set"-dict.  One of my points on the todo-list is to kill the old "incompatbility flags" - but I also made a policy that every feature in the new "feature set" should be tested by the caldav-server-tester.  It does take some time to write those checks - this has proved to be a major tarpit as there are A LOT of flags in that old incompatibility flags.  I have to toss the towel on this one.  I'm again cheating, to make the roadmap look nice with closed issues I will close the current issue and create a new one for mopping up all of them.
* A lot of time has been spent running tests towards external servers.  Testing everything towards external servers is also a major tarpit and a pain, particularly when changing how those compatibility issues are handled as things are bound to break.  Whenever tests are breaking, it's it may be needed to do a lot of research, sometimes the problem is in the test, other times (very rarely) bugs in the code, quite often it's due to changes and upgrades on the server side, sometimes my test account has simply been deactivated.  The pain will hopefully be less for the future, now that the caldav-server-tester is getting good.  It will also feel more rewarding now that compatibility issues are handled by making useful workarounds in the library rather than making workarounds in the test code.
* Another major rabbit hole: 8 hours estimation to "add more servers to the testing".  A new framework for spinning up test servers in internal docker containers - so far Cyrus, Nextcloud, SOGo and Baikal is covered.  I thought the very purpose of Docker was to make operations like this simple and predictable, unfortunately a lot of time has been spent getting those.  In addition there were always compatibility problems causing test runs to fail, and hard debugging sessions.  I estimate that I spent 4 hours by average for each server added, and there are 5 of them now.
